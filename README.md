# AI
**Кейс для Т-Образования.**\
*Задача*: Создать REST API сервис, который сможет обнаруживать логотип Т-Банка (игнорируя логотипы "Тинькофф") на загружаемых изображениях и возвращать координаты найденных логотипов.

# Оглавление:
1. [План работ](#План-работ)
2. [Технологический стек](#технологический-стек)
3. [Ход выполения](#ход-выполения)
4. [Инструкции по установке](#инструкции-по-установке)
5. [Документация решения](#документация-решения)

<br><br/>
---
<br><br/>

# План работ:
В этом разделе вы найдёте задачи, которые были выполнены в рамках проекта и те, что ещё предстоит выполнить.
- [ ] Подготовка данных и разметка (*04-10.09.2025*)
  - [x] Установка зависимостей (*04.09.2025*)
  - [x] Проверка совместимости компонетов (*04.09.2025*)
  - [x] Создайте Dockerfile
  - [x] Разработка предварительной архитектуры (*05.09.2025*)
  - [ ] Дополнение датасета (если потребуется)
  - [ ] Разметка датасета zero-shot с CLIP (*11-12.09.2025*)
  - [ ] Разделение на train/val и финализация (*12.09.2025*)
  - [ ] Проверка (*12.09.2025*)

- [ ] Обучение модели (*12-15.09.2025*)
  - [ ] Создание скриптов (*12.09.2025*)
  - [ ] ...
     
- [ ] Реализация API сервиса (*11-12.09.2025*)
  - [ ] Создание FastAPI-приложения с эндпоинтом /detect: загрузка файла, обработка моделью, возврат DetectionResponse.(*11-12.09.2025*)
  - [ ] Тестирование и отладка (*11-12.09.2025*)
     
- [ ] Валидация и метрики (*14-16.09.2025*)
  - [ ] Написать Python-скрипт для подсчета Precision/Recall/F1 на val-наборе.
  - [ ] Использовать OpenCV для отрисовки bounding boxes на изображениях.
     
- [ ] Доработка
  - [ ] Форматирование проверка и дополнение документации

<br><br/>
---
<br><br/>

# Технологический стек
Данный раздел описывает оптимальный технологический стек для реализации проекта детекции логотипа Т-Банка на основе машинного обучения и REST API. Стек выбран с учетом требований кейса (производительность на GPU T4, ограничения по времени ≤10 с, поддержка форматов изображений, интеграция zero-shot подходов) и известных трендов разработки (на момент составления).

| Категория |	Компонент	| Версия | Обоснование и цель |
| --- | --- | --- | --- |
| Язык программирования	| Python	| 3.13	| Базовый язык для всего проекта. Python 3.13 предлагает улучшенную производительность в async/await (лучше чем 3.12), что идеально для FastAPI-инференса. Использование cpython 3.13.0+ для оптимизаций в ML-задачах. |
| Фреймворк API |	FastAPI + Pydantic |	FastAPI 0.115+, Pydantic 2.10+ |	Для строгого REST API с автогенерацией документации (Swagger). Pydantic обеспечивает валидацию входных данных (размеры изображений, форматы). Поддерживает async для параллельной обработки изображений, укладываясь в 10-сек лимит. |
| Сервер ASGI |	Uvicorn |	0.31+ |	Запуск FastAPI в продакшн. Легкий, быстрый, с поддержкой нескольких GPU. |
| ML-фреймворк |	PyTorch	| 2.4+	| Основной для нейронных сетей (YOLO, CLIP). Версии 2.4+ имеют улучшенный инференс с TorchCompile JIT. **Требует CUDA 11.8+ для GPU (T4): pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118.** |
| Модели ML |	YOLOv8 (ultralytics) |	8.3+	| Для детекции объектов (*bounding boxes логотипа*). YOLOv8 (2023) на 10-20% точнее и быстрее YOLOv5, поддерживает zero-shot и custom datasets. _Альтернатива: YOLOv9/10 для future-proofing, если точность <25%._ |
| Zero-shot ML |	CLIP (OpenAI, via transformers) |	Hugging Face transformers 4.46+ |	Для zero-shot классификации логотипов без полного датасета. Интегрируется с PyTorch; использование model "openai/clip-vit-base-patch16" для speed/accuracy. |
| Обработка изображений |	OpenCV + Pillow	| OpenCV 4.10+, Pillow 11.0+ |	OpenCV для предобработки (*grayscale, resize*), Pillow для загрузки/сохранения внешних форматов (JPEG, PNG, BMP, WEBP). Дополняют друг друга без конфликтов. |
| HTTP-клиент	| Requests	| 2.32+	| Для загрузки изображений по URL (асинхронно в FastAPI). Простой и надежный. |
| Контейнеризация |	Docker	| 27+	| Для iso-пакетарования приложения. **Добавить multi-stage builds для уменьшения размера образа**. |
| GPU-ускорение	| CUDA Toolkit	| 12.6+ |	Для PyTorch GPU. **На T4: установить drivers NVIDIA 470+**. |
| Тестирование и валидация	| Pytest + Sklearn + TorchEval	| Pytest 8.3+, Sklearn 1.5+, TorchEval 1.2+	| Pytest для unit/integration tests. Sklearn/TorchEval для ML-метрик (F1-score, Precision/Recall при IoU=0.5). ***Убедитться, что модель достигает 25% точности на тестовом сете***. |
| Логирование и мониторинг	| Loguru + prometheus-fastapi-instrumentator	| Loguru 0.7+, prometheus-fastapi 2.0+	| Loguru для структурированных логов (ошибки, timeouts). Prometheus для метрик internal (inference time, GPU usage) — **интегрировать с Grafana**. |
| Дополнительные утилиты	| NumPy, Matplotlib	| NumPy 2.1+, Matplotlib 3.9+	| NumPy для векторных операций. Matplotlib для визуализации результатов (bounding boxes на изображениях) в документах/отчетах. |

### Комментарии к установке и зависимостям
GPU check: добавить в код torch.cuda.is_available() для верификации T4.

<br><br/>
---
<br><br/>

# Ход выполения
В этом разделе зафиксированы все шаги, сделанные в рамках этого кейса.
1. Был составлен примерный план работ и первичная документация на основе: <ins>анализа задачи</ins>, <ins>поиска аутуальных технологий</ins> (*открытые источники и нейросети*) и <ins>тайм менеджмента</ins>. (*2 час*)
2. В рамках этапа *установка зависимостей* были проделаны следующие шаги: (*1,5 часа*)
  _ Для повышения удобства использования были созданы .bat файлы, автоматизирующие установку;
  _ Протестированы зависимости;
  _ Обновлена документация.
3. Создана примерная структура проекта. Подключен и проверен докер. (*0,5 часа*)
4. В связи с болезнью и большим количеством неотложных дел (управление проектами, составление программы для Движения первых, проведение лекций) решение кейса было отложено до 11 числа.

<br><br/>
---
<br><br/>

# Инструкции по установке
В этом разделе указаны инструкции по установке проекта и его развёртыванию.<br><br/>
Если вы скачали и распоковали репозиторий, то для полной установки проекта вам осталось:
1. Загрузить датасет.
2. Запустить файл ***run.bat*** и следовать инструкциям.<ins>(***Реализовать выбор режимов***)</ins>
Приятного использования ;)

Для пересборки проекта необходимо:
1. Установить **_python 3.13.*_**;
2. Убедиться, что у вас стабильное подключение к интернету;
3. Запустить файл ***build_docker.bat*** и дождаться завершения его выполнения (*может занять от 5 до 35 минут*).
<br><br/>

<br><br/>
---
<br><br/>

# Документация решения
Этот раздел посвящён детальному описанию решения.
<br><br/>
В целях улучшения пользовательского опыта сборка и запуск решения полностью перенесены в исполняемые файлы (*.bat выбраны за простоту их создания и достаточность интерфейса для этих задач*). 

## Структура проекта
project-root/
├── data/                    # Данные (input/output, если локально; или ссылки на диск)
│   ├── input/              # Исходные данные (изображения для YOLO)
│   └── models/             # Скачанные/обученные модели (yolov8.pt)
├── src/                    # Основной код (разбито по модулям)
│   ├── __init_._.py         # Пустой файл для Python-пакета
│   ├── main.py             # Точка входа: FastAPI app + инициализация
│   ├── api/                # API-эндпоинты
│   │   ├── __init_._.py
│   │   ├── routes.py       # Маршруты (POST /detect, GET /health)
│   │   └── depends.py      # Зависимости
│   ├── services/           # Бизнес-логика (обработка запросов)
│   │   ├── __init_._.py
│   │   ├── ml_service.py   # Инференс YOLO: загрузка модели, предсказания
│   │   └── image_service.py # Обработка изображений (resize, preprocess)
│   └── models/             # Переиспользуемые модели/Pydantic
│       ├── __init_._.py
│       └── schemas.py      # Схемы запросов/ответов (ImageRequest, DetectionResponse)
├── configs/               # Конфигурации (заменяют хардкод)
│   ├── __init_._.py
│   └── config.yaml        # Параметры (порт, модель_path, GPU флаги)
├── tests/                 # Тесты (pytest для микротестов)
│   ├── __init_._.py
│   ├── test_api.py      # Тесты эндпоинтов
│   └── test_ml.py       # Тесты ML-службы
├── scripts/              # Скрипты (запросы, предобработка)
│   └── setup_models.py  # Скачивание моделей (если не вручную)
├── Dockerfile            # Контейнер
├── requirements.txt      # Зависимости (fastapi, torch, ultralytics, opencv, ...)
├── build_docker.bat # Файл запуска сборки проекта
├── run.bat               # Файл запуска проекта
├── README.md
└── .gitignore

<br><br/>

Система разбита на этапы, соответствующие этапам решения кейса:
1. Подготовка и разметка датасета
2. Обучение модели
3. Тестирование модели
4. Имитация использования (*имитация, так как фронтенд в кейсе не требуется, а время не резиновое у меня и других дел/проектов хватает*)

## Подготовка и разметка датасета
...
<br><br/>

## Обучение модели
...
<br><br/>

## Тестирование модели
...
